---
date: "2020-09-19"
description: 
draft: false
image: pay_discrimiation.jpg
keywords: ""
slug: blog8
title: Pay Discrimination Analysis at Omega
---



<pre><code>## ── Attaching packages ──────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
## ✓ tibble  3.0.3     ✓ dplyr   1.0.0
## ✓ tidyr   1.1.0     ✓ stringr 1.4.0
## ✓ readr   1.3.1     ✓ forcats 0.5.0</code></pre>
<pre><code>## ── Conflicts ─────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Loading required package: ggformula</code></pre>
<pre><code>## Loading required package: ggstance</code></pre>
<pre><code>## 
## Attaching package: &#39;ggstance&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:ggplot2&#39;:
## 
##     geom_errorbarh, GeomErrorbarh</code></pre>
<pre><code>## 
## New to ggformula?  Try the tutorials: 
##  learnr::run_tutorial(&quot;introduction&quot;, package = &quot;ggformula&quot;)
##  learnr::run_tutorial(&quot;refining&quot;, package = &quot;ggformula&quot;)</code></pre>
<pre><code>## Loading required package: mosaicData</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:tidyr&#39;:
## 
##     expand, pack, unpack</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;mosaic&#39;:
##   method                           from   
##   fortify.SpatialPolygonsDataFrame ggplot2</code></pre>
<pre><code>## 
## The &#39;mosaic&#39; package masks several functions from core packages in order to add 
## additional features.  The original behavior of these functions should not be affected by this.
## 
## Note: If you use the Matrix package, be sure to load it BEFORE loading mosaic.
## 
## Have you tried the ggformula package for your plots?</code></pre>
<pre><code>## 
## Attaching package: &#39;mosaic&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:Matrix&#39;:
## 
##     mean</code></pre>
<pre><code>## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     count, do, tally</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     cross</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     stat</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,
##     quantile, sd, t.test, var</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     max, mean, min, prod, range, sample, sum</code></pre>
<pre><code>## 
## Attaching package: &#39;ggthemes&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:mosaic&#39;:
## 
##     theme_map</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;GGally&#39;:
##   method from   
##   +.gg   ggplot2</code></pre>
<pre><code>## here() starts at /Users/malaymemani/Desktop/LBS/my_website</code></pre>
<pre><code>## 
## Attaching package: &#39;skimr&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:mosaic&#39;:
## 
##     n_missing</code></pre>
<pre><code>## 
## Attaching package: &#39;janitor&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     chisq.test, fisher.test</code></pre>
<pre><code>## Loading required package: lubridate</code></pre>
<pre><code>## 
## Attaching package: &#39;lubridate&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     date, intersect, setdiff, union</code></pre>
<pre><code>## Loading required package: PerformanceAnalytics</code></pre>
<pre><code>## Loading required package: xts</code></pre>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## 
## Attaching package: &#39;zoo&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<pre><code>## 
## Attaching package: &#39;xts&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     first, last</code></pre>
<pre><code>## 
## Attaching package: &#39;PerformanceAnalytics&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:graphics&#39;:
## 
##     legend</code></pre>
<pre><code>## Loading required package: quantmod</code></pre>
<pre><code>## Loading required package: TTR</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;quantmod&#39;:
##   method            from
##   as.zoo.data.frame zoo</code></pre>
<pre><code>## Version 0.4-0 included new data defaults. See ?getSymbols.</code></pre>
<pre><code>## ══ Need to Learn tidyquant? ═════════════════════════════════════════════════════════════════════════════════════════════════════════════════
## Business Science offers a 1-hour course - Learning Lab #9: Performance Analysis &amp; Portfolio Optimization with tidyquant!
## &lt;/&gt; Learn more at: https://university.business-science.io/p/learning-labs-pro &lt;/&gt;</code></pre>
<pre><code>## 
## Attaching package: &#39;infer&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:mosaic&#39;:
## 
##     prop_test, t_test</code></pre>
<pre><code>## Loading required package: airports</code></pre>
<pre><code>## Loading required package: cherryblossom</code></pre>
<pre><code>## Loading required package: usdata</code></pre>
<pre><code>## 
## Attaching package: &#39;openintro&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:mosaic&#39;:
## 
##     dotPlot</code></pre>
<pre><code>## The following objects are masked from &#39;package:lattice&#39;:
## 
##     ethanol, lsegments</code></pre>
<p>At the last board meeting of Omega Group Plc., the headquarters of a large multinational company, the issue was raised that women were being discriminated in the company, in the sense that the salaries were not the same for male and female executives. A quick analysis of a sample of 50 employees (of which 24 men and 26 women) revealed that the average salary for men was about 8,700 higher than for women. This seemed like a considerable difference, so it was decided that a further analysis of the company salaries was warranted.</p>
<div id="loading-the-data" class="section level2">
<h2>Loading the data</h2>
<p>Loading the data set and providing summary statistics.</p>
<pre class="r"><code>omega &lt;- read_csv(here::here(&quot;data&quot;, &quot;omega.csv&quot;)) # loading data set </code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   salary = col_double(),
##   gender = col_character(),
##   experience = col_double()
## )</code></pre>
<pre class="r"><code>skim(omega) # examine the data frame</code></pre>
<table>
<caption>(#tab:load_omega_data)Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">omega</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">50</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">3</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">2</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">gender</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">6</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">salary</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">68717.06</td>
<td align="right">8638.16</td>
<td align="right">47032.57</td>
<td align="right">63303.16</td>
<td align="right">68847.02</td>
<td align="right">74777.66</td>
<td align="right">84576.11</td>
<td align="left">▁▃▇▆▅</td>
</tr>
<tr class="even">
<td align="left">experience</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">13.98</td>
<td align="right">11.87</td>
<td align="right">0.00</td>
<td align="right">2.25</td>
<td align="right">15.00</td>
<td align="right">20.75</td>
<td align="right">44.00</td>
<td align="left">▇▃▅▂▁</td>
</tr>
</tbody>
</table>
<p>There are no missing variables in the data frame</p>
</div>
<div id="relationship-salary---gender" class="section level2">
<h2>Relationship Salary - Gender ?</h2>
<p>Overall salaries by gender are analysed below in visual and tabular form.</p>
<pre class="r"><code># Examining the overall salaries by gender via boxplot
omega %&gt;% 
  ggplot(aes(x=gender, y=salary, fill=gender)) + # specifying the axes and colouring
        geom_boxplot(alpha=0.3) + # creating a boxplot and setting transparency 
        theme_bw() + # adding a black and white theme
        labs(title = &quot;The median salary for men is higher at Omega overall&quot;, x = &quot;Gender&quot;, y = &quot;Salary&quot;) # labelling title and axes</code></pre>
<p><img src="/blogs/blog8_files/figure-html/confint_single_valiables-1.png" width="672" /></p>
<pre class="r"><code># Examining key salary statistics by gender in a tabular fashion
df_by_gender&lt;-mosaic::favstats (salary ~ gender, data=omega) # using favstats by specifying the variables of interest and data frame
df_by_gender %&gt;% head()</code></pre>
<pre><code>##   gender      min       Q1   median       Q3      max     mean       sd  n
## 1 female 47032.57 60337.83 64618.21 70033.15 78800.18 64542.84 7567.265 26
## 2   male 54768.19 68331.31 74674.51 78568.11 84576.11 73239.13 7462.599 24
##   missing
## 1       0
## 2       0</code></pre>
<p>As can be seen in the boxplot, the median salary for men is significantly higher than women on an overall basis. This is indicative of the fact that more men are getting paid higher than women. Besides, looking at the distribution statistics from the table it seems like the average pay for men is also significantly greater. This analysis needs to be looked at from a experience perspective, which has been done below.</p>
<pre class="r"><code># Dataframe with two rows (male-female) and having as columns gender, mean, SD, sample size, 
# the t-critical value, the standard error, the margin of error, 
# and the low/high endpoints of a 95% confidence interval

df_by_gender2&lt;- df_by_gender %&gt;% # creating a new variable
  mutate(t_critical=qt(.975,n-1), # calculating T value
         standard_error=sd/sqrt(n), # calculating standard error
         upper_95=mean+t_critical*standard_error, # calculating upper CI
         lower_95=mean-t_critical*standard_error) %&gt;% # calculating lower CI
  select(gender,mean,sd,n,t_critical,standard_error,upper_95,lower_95) # selecting variables to display

df_by_gender2</code></pre>
<pre><code>##   gender     mean       sd  n t_critical standard_error upper_95 lower_95
## 1 female 64542.84 7567.265 26   2.059539       1484.063 67599.32 61486.35
## 2   male 73239.13 7462.599 24   2.068658       1523.297 76390.31 70087.95</code></pre>
<pre class="r"><code># We can see that the confidence intervals for men and women in regards to salary do not overlap. This would allow us to reject the null hypothesis, but we will carry out hypothesis testing anyway and analyse the relationships between all the remaining factors.

#We will draw a scatterplot to visually inspect relationship between salary and experience

ggplot(omega,aes(x=experience,y=salary, colour= gender,fill=gender)) + # specifying axes and colour
  geom_point() + # creating a scatter plot
  geom_smooth() + # adding a trend line
  labs(title = &quot;Experience is Valued Highly at Omega&quot;, x=&quot;Years of experience&quot;, y= &quot;Salary (in USD)&quot;) + # labelling title and axes 
  theme_bw() # adding a black and white theme </code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/blog8_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>We can observe a strong relationship between salary and experience. Increase in salary comes quickly at the beginning and throughout the first ~15 years, however the gains in salary become slower later over time, displaying diminishing marginal returns. We can also observe that, at the beginning of an employee’s career, women are paid relatively higher with a tighter 95% confidence interval. With the increase in years of experience salaries of women reduce as opposed to men. A probable reason maybe that once women have families their responsibilities at home increase and Omega’s policies doesn’t seem to be supportive of this fact.</p>
<p>We will further investigate the difference between salaries by gender through hypothesis testing, utilizing both t.test() and the simulation method from the infer package.</p>
<pre class="r"><code># hypothesis testing using t.test() 
t.test(salary~gender, data=omega) # conducting sample t test </code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  salary by gender
## t = -4.0891, df = 47.78, p-value = 0.0001651
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -12972.825  -4419.755
## sample estimates:
## mean in group female   mean in group male 
##             64542.84             73239.13</code></pre>
<pre class="r"><code># hypothesis testing using infer package
set.seed(12345) # setting the seed for reproducability
salary_by_gender&lt;- omega %&gt;%  # creating a variable
  specify(salary~gender) %&gt;% # specifying the variable of interest
  hypothesize(null=&quot;independence&quot;) %&gt;% # stating the null hypothesis  
  generate(reps=1000,type=&quot;permute&quot;) %&gt;% # generating replicas
  calculate(stat=&quot;diff in means&quot;,
            order=c(&quot;male&quot;,&quot;female&quot;)) # calculating the key sample statistic ordered by sex 

# visualising simulation based null hypothesis 
salary_by_gender %&gt;% 
  visualize() + # generating the graph
  shade_p_value(obs_stat = df_by_gender2[2,2]-df_by_gender2[1,2], direction = &quot;both&quot;) + # creating the line with P value 
  labs(x = &quot;Diff in Salaries&quot;) + # labelling the x axis 
  theme_bw() # adding a black and white theme</code></pre>
<p><img src="/blogs/blog8_files/figure-html/hypothesis_testing-1.png" width="672" /></p>
<pre class="r"><code>#getting p value for conclusion

p_value_by_gender&lt;-salary_by_gender %&gt;% # creating a new variable
  get_p_value(obs_stat = df_by_gender2[2,2]-df_by_gender2[1,2], direction = &quot;both&quot;) # generating P value </code></pre>
<pre><code>## Warning: Please be cautious in reporting a p-value of 0. This result is an
## approximation based on the number of `reps` chosen in the `generate()` step. See
## `?get_p_value()` for more information.</code></pre>
<pre class="r"><code>p_value_by_gender</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1       0</code></pre>
<pre class="r"><code>#p_value is tiny, so the null hypothesis can be rejected</code></pre>
<p>Looking at the graph the x axis ends at 10,000 dollars. The difference in the mean values of the gender salaries is 8,696 dollars. It can be seen that this results in a p-value close enough to zero, therefore at a 5% significance level there is a meaningful difference between the mean salaries of men and women.</p>
</div>
<div id="relationship-experience---gender" class="section level2">
<h2>Relationship Experience - Gender?</h2>
<p>At the board meeting, someone raised the issue that there was indeed a substantial difference between male and female salaries, but that this was attributable to other reasons such as differences in experience. A questionnaire send out to the 50 executives in the sample reveals that the average experience of the men is approximately 21 years, whereas the women only have about 7 years experience on average (see table below).</p>
<pre class="r"><code># Summary Statistics of salary by gender
omega %&gt;% 
  ggplot(aes(x = gender, y = experience, fill=gender)) + # specifying axes
  geom_boxplot(alpha=0.3) # creating a boxplot</code></pre>
<p><img src="/blogs/blog8_files/figure-html/experience_stats-1.png" width="672" /></p>
<pre class="r"><code>stats_exp_gender &lt;- favstats (experience ~ gender, data=omega) # using favstats by specifying the variables of interest and data frame</code></pre>
<p>It seems from the graph and the table that Omega has relatively less experienced women employees.</p>
<p>95% confidence intervals and a hypothesis test for analysing experience by gender has been done below.</p>
<pre class="r"><code># Calculate 95% confidence intervals for experience by gender
exp_gender_ci &lt;- omega %&gt;% # creating a new variable
  group_by(gender) %&gt;% # grouping by gender
  summarise(mean_exp = mean(experience), # calculating the mean of experience 
            sd_exp = sd(experience), # calculating the standard deviation of experience
            count = n(), # counting employees by gender
            t_critical = qt(0.975, count -1), # calculating the T value
            se_exp = sd_exp/sqrt(count), # calculating standard error
            margin_of_error_exp = t_critical * se_exp, # calculating margin of error
            exp_low = mean_exp - margin_of_error_exp, # calculating lower CI
            exp_high = mean_exp + margin_of_error_exp) # calculating upper CI</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre class="r"><code>exp_gender_ci</code></pre>
<pre><code>## # A tibble: 2 x 9
##   gender mean_exp sd_exp count t_critical se_exp margin_of_error… exp_low
##   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt;  &lt;dbl&gt;            &lt;dbl&gt;   &lt;dbl&gt;
## 1 female     7.38   8.51    26       2.06   1.67             3.44    3.95
## 2 male      21.1   10.9     24       2.07   2.23             4.61   16.5 
## # … with 1 more variable: exp_high &lt;dbl&gt;</code></pre>
<pre class="r"><code># We can see that the confidence intervals for men and women in regards to experience do not overlap. This would allow us to reject the null hypothesis, but we will carry out hypothesis testing anyway.

#t-test
t.test(experience~gender, data=omega, var.equal = FALSE) # generating T test</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  experience by gender
## t = -4.9348, df = 43.472, p-value = 1.225e-05
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -19.353881  -8.126888
## sample estimates:
## mean in group female   mean in group male 
##             7.384615            21.125000</code></pre>
<pre class="r"><code>#the t-test shows that we can accept the alternative hypothesis, there is a significant difference in means of experience by gender. We get a tiny p-value reported at 1e-05, so almost zero

# permutation test
set.seed(1234) # setting seed for reproducability 
 
  experience_in_null &lt;- omega %&gt;% # creating new variable
    specify(experience ~ gender) %&gt;% # specifying variables
    hypothesize(null = &quot;independence&quot;) %&gt;% # hypothesising the null
    generate(reps = 1000, type = &quot;permute&quot;) %&gt;% # generating replicas
    calculate(stat = &quot;diff in means&quot;, # calculating the key stat
              order = c(&quot;female&quot;, &quot;male&quot;))
  
  experience_in_null %&gt;% visualize() + # generating the graph
    shade_p_value(obs_stat = exp_gender_ci[2,2]-exp_gender_ci[1,2], direction = &quot;both&quot;) # creating the line with P value</code></pre>
<p><img src="/blogs/blog8_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>#now getting p value for conclusion

p_value_exp_gender &lt;- experience_in_null %&gt;% # creating a new variable
  get_p_value(obs_stat = exp_gender_ci[2,2]-exp_gender_ci[1,2], direction = &quot;both&quot;) # generating P value </code></pre>
<pre><code>## Warning: Please be cautious in reporting a p-value of 0. This result is an
## approximation based on the number of `reps` chosen in the `generate()` step. See
## `?get_p_value()` for more information.</code></pre>
<pre class="r"><code>p_value_exp_gender</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1       0</code></pre>
<p>The person who raised the issue at the board meeting was correct in assuming that there is a statistically significant difference between the mean levels of experience for males and females in the company. However, this does not justify the difference in salaries of men and women at the same relatively same level of experience. It also signifies that for more experienced/senior roles Omega prefers men.</p>
</div>
<div id="relationship-salary---experience" class="section level2">
<h2>Relationship Salary - Experience ?</h2>
<p>Someone at the meeting argues that clearly, a more thorough analysis of the relationship between salary and experience is required before any conclusion can be drawn about whether there is any gender-based salary discrimination in the company.</p>
<p>Analyse the relationship between salary and experience. Draw a scatterplot to visually inspect the data.</p>
<pre class="r"><code>#We will draw a scatterplot to visually inspect relationship between salary and experience

  ggplot(omega,aes(x=experience,y=salary, colour= gender,fill=gender)) + # specifying axes
  geom_point() + # creating scatter plot
  geom_smooth(method = &#39;gam&#39;) + # adding a trend line
  labs(title = &quot;We can observe a strong relationship between salary and experience&quot;, x=&quot;Years of experience&quot;, y= &quot;Salary&quot;) + # labelling title and axes
  theme_bw() + # adding a black and white theme
  scale_y_continuous(labels= scales::dollar) # scalling the y axis by USD</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39;</code></pre>
<p><img src="/blogs/blog8_files/figure-html/salary_exp_scatter-1.png" width="672" /></p>
<pre class="r"><code>#We can observe a strong relationship between salary and experience. Increase in salary comes quickly at the beginning throughout first ~15 years, however the gains in salary become slower later over time.</code></pre>
<p>As can be seen, there is a significant positive relationship between years of experience and salary. It can also be seen what was confirmed in the previous section, that women have significantly less experience than men, with a cut off point displayed above at around 30 years. This gives an alternative reasoning besides discrimination regarding the pay gap, as more years of experience are a valuable asset that is accordingly financially rewarded with a greater salary.</p>
<p>Another intersting perspective can be that more men are hired with higher years of experience than women. If a true comparison has to be made between the salaries of the two groups, both should have comparable distribution of years of experience which is not the case. Hence, no conclusion about the original question can be drawn from the above analysis</p>
</div>
<div id="correlations-between-the-data" class="section level2">
<h2>Correlations between the data</h2>
<pre class="r"><code>omega %&gt;% 
  select(gender, experience, salary) %&gt;% #order variables they will appear in ggpairs()
  ggpairs(aes(colour=gender, alpha = 0.3))+
  theme_bw()</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="/blogs/blog8_files/figure-html/ggpairs-1.png" width="672" /></p>
<p>From the scatterplot we can see that the majority of women in the sample have a comparable salary to men with the same experience level.</p>
<p>The majority of women in the sample have experience between 0 and 20 years, whereas the approximate range of experience for most men is between 10 and 35 years. We also saw above that there is a statistically significant difference between the levels of experience for both genders, which confirms what we are seeing. Women seem to end their careers earlier, at least within the given sample.</p>
<p>Based on the sample, it can be seen in the graphical summarisation presented above, that majority of women in the sample have less than 20 years of experience indicating that they either leave their careers early or Omega’s policies is biased towards men with higher years of experience as mentioned above. Additionally, as salaries increase with experience it can be seen why the average pay in women is less than men - because there are less women with HIGH EXPERIENCE.</p>
</div>
